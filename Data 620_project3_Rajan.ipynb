{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev- test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nltk library was of the utmost importance in this project; it was used for the names corpus and for its classifiers. The library random was used for shuffling the names, and pandas was used for creating a function to test the accuracy of the final gender-predicting function more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names provided by nltk were utilized for training and testing our algorithms, with male and female names being stored in a single variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determination of accuracy\n",
    "When creating a function for determining the accuracy of any given combination of features, it was determined the Naive Bayes method of classification would be best suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(number_of_runs, function_to_use):\n",
    "    acc_df = {\n",
    "        \"classifier\": [],\n",
    "        \"train_set_accuracy\": [],\n",
    "        \"test_set_accuracy\": [],\n",
    "        \"devtest_set_accuracy\": [],\n",
    "        \"devtest_errors\": []\n",
    "    }\n",
    "    for i in range(number_of_runs):\n",
    "        random.shuffle(names)\n",
    "        acc_train_names = names[1000:]\n",
    "        acc_devtest_names = names[500:1000]\n",
    "        acc_test_names = names[:500]\n",
    "        acc_train_set = [(function_to_use(n), g) for (n,g) in acc_train_names]\n",
    "        acc_devtest_set = [(function_to_use(n), g) for (n,g) in acc_devtest_names]\n",
    "        acc_test_set = [(function_to_use(n), g) for (n,g) in acc_test_names]\n",
    "        acc_classifier = nltk.NaiveBayesClassifier.train(acc_train_set)\n",
    "        acc_df[\"classifier\"].append(acc_classifier)\n",
    "        acc_df[\"train_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_train_set))\n",
    "        acc_df[\"test_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_test_set))\n",
    "        acc_df[\"devtest_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_devtest_set))\n",
    "        acc_errors = []\n",
    "        for (name, tag) in acc_devtest_names:\n",
    "            acc_guess = acc_classifier.classify(function_to_use(name))\n",
    "            if acc_guess != tag:\n",
    "                acc_errors.append( (tag, acc_guess, name) )\n",
    "        acc_df[\"devtest_errors\"].append(acc_errors)\n",
    "    acc_df = pd.DataFrame.from_dict(acc_df)\n",
    "    return(acc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary was later transformed into a data frame would be created to store the number of runs performed for the given created function for checking features against the names in the names variable. This is why this function, accuracy, has a parameter called number_of_runs, to determine how many times a given function should be run before being considered accurate. Ultimately the number settled on was 100.\n",
    "\n",
    "Within the accuracy function itself the names were shuffled for every run; for each shuffling of the names, the first 500 names would be used as a test set, the next 500 for the dev test, and the remaining names for the training set. The classifiers for each run were kept, as were the list of errors.\n",
    "\n",
    "Lastly, the data frame would be returned, best stored in another user-defined variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender features\n",
    "Natural Language Processing with Python, Chapter 6, provided two premade functions with features to check against the corpus of names,a third function was created to compare against the accuracy of with the textbook's examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textbook_gender_features_1(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the textbook's first example of testing for gender features. All it tests for is the last letter of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textbook_gender_features_2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the textbook's second example of testing for gender features. It expands upon the previous example by checking for the last letter of a given name, but also by looking into the first letter, the number of times each letter appears, and whether or not the letter was present in the name at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_gender_features(name):\n",
    "    features = {}\n",
    "    temp_name = name\n",
    "    eng_cons_clusters = [\"bl\", \"br\", \"ch\", \"cl\", \"cr\", \"dr\", \"fl\", \"fr\", \"gl\", \"gr\", \"pl\", \"pr\", \"sc\", \"sh\", \"sk\", \"sl\", \"sm\", \"sn\", \"sp\", \"st\", \"sw\", \"th\", \"tr\", \"tw\", \"wh\", \"wr\", \"sch\", \"scr\", \"shr\", \"sph\", \"spl\", \"spr\", \"squ\", \"str\", \"thr\"]\n",
    "    features[\"firstletter\"] = name[0].lower() \n",
    "    features[\"lastletter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    clusters = []\n",
    "    for cluster in eng_cons_clusters[::-1]:\n",
    "        if cluster in temp_name:\n",
    "            temp_name = temp_name.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"english_consonant_clusters_1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"english_consonant_clusters_2\"] = clusters[1] if len(clusters) > 1 else None\n",
    "    features[\"english_consonant_clusters_3\"] = clusters[2] if len(clusters) > 2 else None\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd function utilizes the first and last letter from the previous text book, but it also looks for the prefix and suffix - or first and last two or three letters, depending on the name's length - of a name and looks for whether or not any of the consonant clusters in English are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy\n",
    "The aim of this project is to imporve the accuracy of the gender feature functions provided by the textbook. To do so, the function is run 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set_accuracy</th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>devtest_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.762978</td>\n",
       "      <td>0.759840</td>\n",
       "      <td>0.759840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.018279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.759649</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.761629</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>0.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.762961</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.764113</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.767425</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.814000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_set_accuracy  test_set_accuracy  devtest_set_accuracy\n",
       "count          100.000000         100.000000            100.000000\n",
       "mean             0.762978           0.759840              0.759840\n",
       "std              0.001871           0.018614              0.018279\n",
       "min              0.759649           0.716000              0.712000\n",
       "25%              0.761629           0.747500              0.747500\n",
       "50%              0.762961           0.760000              0.761000\n",
       "75%              0.764113           0.772500              0.772000\n",
       "max              0.767425           0.808000              0.814000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook_df_1 = accuracy(100, textbook_gender_features_1)\n",
    "textbook_df_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function, while simplistic, has fairly impressive results; the average accuracy across the board is between 76.1% and 76.3%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set_accuracy</th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>devtest_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.778291</td>\n",
       "      <td>0.773120</td>\n",
       "      <td>0.77314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.01776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.73200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.778226</td>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.77400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.779558</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.78650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.783842</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.81600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_set_accuracy  test_set_accuracy  devtest_set_accuracy\n",
       "count          100.000000         100.000000             100.00000\n",
       "mean             0.778291           0.773120               0.77314\n",
       "std              0.002040           0.016736               0.01776\n",
       "min              0.774338           0.738000               0.73200\n",
       "25%              0.776642           0.760000               0.76000\n",
       "50%              0.778226           0.774000               0.77400\n",
       "75%              0.779558           0.784000               0.78650\n",
       "max              0.783842           0.804000               0.81600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook_df_2 = accuracy(100, textbook_gender_features_2)\n",
    "textbook_df_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function provided by the textbook, while slightly more complex, had an average accuracy across the board that ranged from 77.4% to 77.8%, looking into a few more features could produce a substantial increase in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set_accuracy</th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>devtest_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.883430</td>\n",
       "      <td>0.830580</td>\n",
       "      <td>0.831060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>0.017267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.880328</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.882344</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.883497</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.884505</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>0.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.887241</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.874000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_set_accuracy  test_set_accuracy  devtest_set_accuracy\n",
       "count          100.000000         100.000000            100.000000\n",
       "mean             0.883430           0.830580              0.831060\n",
       "std              0.001477           0.016537              0.017267\n",
       "min              0.880328           0.796000              0.786000\n",
       "25%              0.882344           0.820000              0.819500\n",
       "50%              0.883497           0.830000              0.833000\n",
       "75%              0.884505           0.842500              0.842000\n",
       "max              0.887241           0.872000              0.874000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_df = accuracy(100, function_gender_features)\n",
    "function_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thrid developed function was more complex than what the textbook offered. It resulted in an average accuracy of 83.1% to 88.3%, and sometimes even higher depending on the run. It succeeded in overcoming the results the textbook provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The challenge to produce a function more accurate than the one provided by the textbooks was accomplished."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
